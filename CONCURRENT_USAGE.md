# å¹¶å‘BigModelæ‰§è¡Œå™¨ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

`concurrent_bigmodel.py` æ˜¯ä¸€ä¸ªæ”¯æŒNä¸ªå¹¶å‘çš„BigModelåˆ†ææ‰§è¡Œå™¨ï¼ŒåŸºäºåŸå§‹çš„ `bigmodel_loop.py` æ‰©å±•è€Œæ¥ã€‚å®ƒæ”¯æŒä¸‰ç§å¹¶å‘æ¨¡å¼ï¼Œæä¾›å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œè¿›åº¦ç›‘æ§ã€‚

## ç‰¹æ€§

- âœ… **å¤šç§å¹¶å‘æ¨¡å¼**: multiprocessingï¼ˆå¤šè¿›ç¨‹ï¼‰, threadingï¼ˆå¤šçº¿ç¨‹ï¼‰, asyncioï¼ˆå¼‚æ­¥ï¼‰
- âœ… **çµæ´»çš„å¹¶å‘æ§åˆ¶**: æ”¯æŒæŒ‡å®šä»»æ„æ•°é‡çš„å¹¶å‘worker
- âœ… **å®Œæ•´çš„é”™è¯¯å¤„ç†**: è¶…æ—¶æ§åˆ¶ã€é‡è¯•æœºåˆ¶ã€å¼‚å¸¸æ•è·
- âœ… **è¿›åº¦ç›‘æ§**: å®æ—¶æ˜¾ç¤ºæ‰§è¡Œè¿›åº¦å’Œç»Ÿè®¡ä¿¡æ¯
- âœ… **ç»“æœè¾“å‡º**: JSONæ ¼å¼çš„è¯¦ç»†ç»“æœä¿å­˜
- âœ… **LangSmithé›†æˆ**: å®Œæ•´æ”¯æŒåˆ†å¸ƒå¼è¿½è¸ª
- âœ… **ä¼˜é›…åœæ­¢**: æ”¯æŒCtrl+Cä¸­æ–­å’Œä¿¡å·å¤„ç†

## å®‰è£…ä¾èµ–

```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# æˆ–è€…å®‰è£…å¼€å‘ä¾èµ–ï¼ˆåŒ…å«æµ‹è¯•å·¥å…·ï¼‰
pip install -r requirements-dev.txt
```

## å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€ä½¿ç”¨

```bash
# ä½¿ç”¨4ä¸ªè¿›ç¨‹å¹¶å‘å¤„ç†é»˜è®¤è¯é¢˜
python concurrent_bigmodel.py

# æŒ‡å®šè¯é¢˜å’Œå¹¶å‘æ•°
python concurrent_bigmodel.py --topics "AIæŠ€æœ¯" "æ–°èƒ½æº" "åŒ»ç–—ç§‘æŠ€" --concurrency 8

# æ— é™æŒç»­æ‰§è¡Œï¼ˆæ¯éš”5ç§’æ‰§è¡Œä¸€è½®ï¼Œç›´åˆ°Ctrl+Cåœæ­¢ï¼‰
python concurrent_bigmodel.py --topics "AIæŠ€æœ¯" "æ–°èƒ½æº" --iterations 0 --delay 5
```

### 2. ä¸åŒå¹¶å‘æ¨¡å¼

```bash
# å¤šè¿›ç¨‹æ¨¡å¼ï¼ˆæ¨èï¼ŒçœŸæ­£çš„å¹¶è¡Œï¼‰
python concurrent_bigmodel.py --mode multiprocessing --concurrency 4

# å¤šçº¿ç¨‹æ¨¡å¼ï¼ˆé€‚åˆI/Oå¯†é›†å‹ï¼‰
python concurrent_bigmodel.py --mode threading --concurrency 8

# å¼‚æ­¥æ¨¡å¼ï¼ˆé«˜æ•ˆçš„I/Oå¤„ç†ï¼‰
python concurrent_bigmodel.py --mode asyncio --concurrency 6
```

### 3. é«˜çº§é…ç½®

```bash
# å®Œæ•´å‚æ•°ç¤ºä¾‹
python concurrent_bigmodel.py \\
    --topics "äººå·¥æ™ºèƒ½" "æœºå™¨å­¦ä¹ " "æ·±åº¦å­¦ä¹ " "ç¥ç»ç½‘ç»œ" "è®¡ç®—æœºè§†è§‰" \\
    --concurrency 6 \\
    --mode threading \\
    --iterations 3 \\
    --timeout 180 \\
    --delay 1.0 \\
    --output results.json \\
    --chat-model glm-4.5-aq \\
    --tool-model glm-4.5-aq

# æ— é™æŒç»­æ‰§è¡Œï¼ˆç›´åˆ°æ‰‹åŠ¨åœæ­¢ï¼‰
python concurrent_bigmodel.py \\
    --topics "AIæŠ€æœ¯" "æ–°èƒ½æº" \\
    --concurrency 4 \\
    --iterations 0 \\
    --delay 10 \\
    --mode multiprocessing
```

## å‚æ•°è¯´æ˜

### åŸºç¡€å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|--------|------|
| `--api-key` | BigModel APIå¯†é’¥ | ç¯å¢ƒå˜é‡`BIGMODEL_API_KEY` | `--api-key your_key` |
| `--topics` | è¦åˆ†æçš„è¯é¢˜åˆ—è¡¨ | 5ä¸ªé»˜è®¤è¯é¢˜ | `--topics "AI" "åŒºå—é“¾"` |
| `--iterations` | æ‰§è¡Œè½®æ•° (0=æ— é™æ‰§è¡Œ) | 1 | `--iterations 3` æˆ– `--iterations 0` |

### å¹¶å‘å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | æ¨èå€¼ |
|------|------|--------|--------|
| `--concurrency` | å¹¶å‘workeræ•°é‡ | 4 | 4-8 |
| `--mode` | å¹¶å‘æ¨¡å¼ | multiprocessing | multiprocessing/threading |
| `--timeout` | å•ä»»åŠ¡è¶…æ—¶(ç§’) | 120 | 60-300 |
| `--delay` | ä»»åŠ¡é—´å»¶è¿Ÿ(ç§’) | 0.5 | 0.5-2.0 |
| `--max-retries` | æœ€å¤§é‡è¯•æ¬¡æ•° | 2 | 1-3 |

### æ¨¡å‹å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--chat-model` | èŠå¤©æ¨¡å‹ | glm-4.5-aq |
| `--tool-model` | å·¥å…·æ¨¡å‹ | glm-4.5-aq |

### è¾“å‡ºå‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--output` | ç»“æœè¾“å‡ºæ–‡ä»¶ | è‡ªåŠ¨ç”Ÿæˆ |
| `--quiet` | é™é»˜æ¨¡å¼ | False |

## æŒç»­æ‰§è¡Œæ¨¡å¼

### ğŸ”„ æ— é™æ‰§è¡Œ (iterations=0)

å¯ç”¨æŒç»­æ‰§è¡Œæ¨¡å¼ï¼Œç¨‹åºä¼šä¸æ–­å¾ªç¯æ‰§è¡Œåˆ†æä»»åŠ¡ï¼Œç›´åˆ°æ‰‹åŠ¨åœæ­¢ï¼š

```bash
# åŸºç¡€æ— é™æ‰§è¡Œ
python concurrent_bigmodel.py --iterations 0 --topics "AIæŠ€æœ¯" "æ–°èƒ½æº"

# å¸¦å»¶è¿Ÿçš„æ— é™æ‰§è¡Œï¼ˆæ¯10ç§’ä¸€è½®ï¼‰
python concurrent_bigmodel.py --iterations 0 --delay 10 --topics "å¸‚åœºåŠ¨æ€" "ç§‘æŠ€çƒ­ç‚¹"

# é«˜å¹¶å‘çš„æ— é™æ‰§è¡Œ
python concurrent_bigmodel.py \\
    --iterations 0 \\
    --concurrency 8 \\
    --mode multiprocessing \\
    --delay 30 \\
    --topics "äººå·¥æ™ºèƒ½" "æ–°èƒ½æº" "åŒ»ç–—ç§‘æŠ€" "æ™ºèƒ½åˆ¶é€ " "é‡‘èç§‘æŠ€"
```

**ç‰¹æ€§:**
- âœ… è‡ªåŠ¨å¾ªç¯æ‰§è¡Œï¼Œæ— éœ€é‡å¯
- âœ… ä¼˜é›…åœæ­¢æ”¯æŒï¼ˆCtrl+Cï¼‰
- âœ… æ¯è½®æ‰§è¡Œç‹¬ç«‹è®°å½•å’Œç»Ÿè®¡
- âœ… æ”¯æŒæ‰€æœ‰å¹¶å‘æ¨¡å¼
- âœ… å®Œæ•´çš„LangSmithè¿½è¸ª

**ä½¿ç”¨åœºæ™¯:**
- ğŸ“Š **å®šæœŸç›‘æ§**: æŒç»­è·Ÿè¸ªç‰¹å®šè¯é¢˜çš„å‘å±•
- ğŸ” **å®æ—¶åˆ†æ**: å¯¹æ—¶æ•ˆæ€§å¼ºçš„å†…å®¹è¿›è¡ŒæŒç»­åˆ†æ
- ğŸ“ˆ **é•¿æœŸè§‚å¯Ÿ**: è§‚å¯Ÿè¶‹åŠ¿å˜åŒ–å’Œå‘å±•æ¨¡å¼
- âš¡ **å‹åŠ›æµ‹è¯•**: æµ‹è¯•ç³»ç»Ÿåœ¨é•¿æ—¶é—´è¿è¡Œä¸‹çš„ç¨³å®šæ€§

**åœæ­¢æ–¹å¼:**
```bash
# æ–¹å¼1: Ctrl+C ä¼˜é›…åœæ­¢
# æ–¹å¼2: å‘é€SIGTERMä¿¡å·
kill -TERM <è¿›ç¨‹ID>

# æ–¹å¼3: ä½¿ç”¨timeoutå‘½ä»¤é™åˆ¶è¿è¡Œæ—¶é—´
timeout 1h python concurrent_bigmodel.py --iterations 0 --topics "AIæŠ€æœ¯"
```

## å¹¶å‘æ¨¡å¼é€‰æ‹©

### ğŸš€ Multiprocessingï¼ˆå¤šè¿›ç¨‹ï¼‰

**æ¨èä½¿ç”¨**ï¼ŒçœŸæ­£çš„å¹¶è¡Œæ‰§è¡Œ

```bash
python concurrent_bigmodel.py --mode multiprocessing --concurrency 4
```

**ä¼˜ç‚¹**:
- çœŸæ­£çš„å¹¶è¡Œæ‰§è¡Œï¼Œä¸å—GILé™åˆ¶
- è¿›ç¨‹é—´éš”ç¦»ï¼Œä¸€ä¸ªè¿›ç¨‹å´©æºƒä¸å½±å“å…¶ä»–
- é€‚åˆCPUå¯†é›†å‹å’ŒI/Oå¯†é›†å‹ä»»åŠ¡

**ç¼ºç‚¹**:
- å¯åŠ¨å¼€é”€è¾ƒå¤§
- å†…å­˜å ç”¨ç›¸å¯¹è¾ƒå¤š

**é€‚ç”¨åœºæ™¯**: å¤§æ‰¹é‡ä»»åŠ¡ï¼Œå¯¹æ€§èƒ½è¦æ±‚é«˜

### ğŸ§µ Threadingï¼ˆå¤šçº¿ç¨‹ï¼‰

```bash
python concurrent_bigmodel.py --mode threading --concurrency 8
```

**ä¼˜ç‚¹**:
- å¯åŠ¨å¿«ï¼Œèµ„æºå ç”¨å°‘
- é€‚åˆI/Oå¯†é›†å‹ä»»åŠ¡
- çº¿ç¨‹é—´é€šä¿¡æ–¹ä¾¿

**ç¼ºç‚¹**:
- å—GILé™åˆ¶ï¼Œä¸æ˜¯çœŸæ­£å¹¶è¡Œ
- çº¿ç¨‹å®‰å…¨éœ€è¦è€ƒè™‘

**é€‚ç”¨åœºæ™¯**: ç½‘ç»œè¯·æ±‚å¯†é›†ï¼Œä¸­ç­‰è§„æ¨¡ä»»åŠ¡

### âš¡ Asyncioï¼ˆå¼‚æ­¥ï¼‰

```bash  
python concurrent_bigmodel.py --mode asyncio --concurrency 6
```

**ä¼˜ç‚¹**:
- é«˜æ•ˆçš„I/Oå¤„ç†
- å•çº¿ç¨‹ï¼Œæ— éœ€è€ƒè™‘çº¿ç¨‹å®‰å…¨
- èµ„æºå ç”¨æœ€å°‘

**ç¼ºç‚¹**:
- å¤æ‚åº¦ç›¸å¯¹è¾ƒé«˜
- ä¸é€‚åˆCPUå¯†é›†å‹ä»»åŠ¡

**é€‚ç”¨åœºæ™¯**: å¤§é‡å¼‚æ­¥I/Oï¼Œå¯¹èµ„æºä½¿ç”¨æ•æ„Ÿ

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. å¹¶å‘æ•°è®¾ç½®

```bash
# æ ¹æ®æœºå™¨é…ç½®è°ƒæ•´
CPU_COUNT=$(nproc)

# I/Oå¯†é›†å‹ï¼ˆæ¨èï¼‰
CONCURRENCY=$((CPU_COUNT * 2))

# CPUå¯†é›†å‹
CONCURRENCY=$CPU_COUNT

# ç¤ºä¾‹ï¼š8æ ¸æœºå™¨
python concurrent_bigmodel.py --concurrency 16  # I/Oå¯†é›†
python concurrent_bigmodel.py --concurrency 8   # CPUå¯†é›†
```

### 2. è¶…æ—¶è®¾ç½®

```bash
# æ ¹æ®ç½‘ç»œå’Œä»»åŠ¡å¤æ‚åº¦è°ƒæ•´
python concurrent_bigmodel.py --timeout 60   # å¿«é€Ÿç½‘ç»œ
python concurrent_bigmodel.py --timeout 180  # æ…¢é€Ÿç½‘ç»œæˆ–å¤æ‚ä»»åŠ¡
```

### 3. æ‰¹é‡å¤„ç†

```bash
# å¤§é‡ä»»åŠ¡æ—¶åˆ†æ‰¹å¤„ç†
python concurrent_bigmodel.py \\
    --topics $(echo {1..100} | tr ' ' '\\n' | sed 's/^/topic_/') \\
    --batch-size 10 \\
    --concurrency 8
```

## ç›‘æ§å’Œè°ƒè¯•

### 1. æ—¥å¿—è¾“å‡º

```bash
# è¯¦ç»†æ—¥å¿—
python concurrent_bigmodel.py --topics "AI" "åŒºå—é“¾"

# é™é»˜æ¨¡å¼
python concurrent_bigmodel.py --quiet --output results.json

# æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶
tail -f concurrent_bigmodel.log
```

### 2. ç»“æœåˆ†æ

```bash
# åˆ†æç»“æœæ–‡ä»¶
python -c "
import json
with open('results.json') as f:
    data = json.load(f)
    print('æ€»ä»»åŠ¡:', data['summary']['total_tasks'])
    print('æˆåŠŸç‡:', f\"{data['summary']['successful_tasks']/data['summary']['total_tasks']*100:.1f}%\")
    print('å¹³å‡è€—æ—¶:', f\"{data['summary']['average_execution_time']:.2f}s\")
"
```

### 3. LangSmithè¿½è¸ª

```bash
# è®¾ç½®LangSmithç¯å¢ƒå˜é‡
export LANGSMITH_API_KEY="your_langsmith_key"
export LANGSMITH_PROJECT="concurrent-bigmodel"

# æ‰§è¡Œå¸¦è¿½è¸ªçš„ä»»åŠ¡
python concurrent_bigmodel.py --topics "AIæŠ€æœ¯" "æ–°èƒ½æº"

# æŸ¥çœ‹è¿½è¸ªç»“æœ
echo "è®¿é—®: https://smith.langchain.com/projects/concurrent-bigmodel"
```

## å¸¸è§é—®é¢˜

### Q1: å‡ºç°è¿æ¥è¶…æ—¶é”™è¯¯ï¼Ÿ

```bash
# å¢åŠ è¶…æ—¶æ—¶é—´å’Œé‡è¯•æ¬¡æ•°
python concurrent_bigmodel.py \\
    --timeout 300 \\
    --max-retries 3 \\
    --delay 2.0
```

### Q2: å†…å­˜å ç”¨è¿‡é«˜ï¼Ÿ

```bash
# é™ä½å¹¶å‘æ•°æˆ–ä½¿ç”¨çº¿ç¨‹æ¨¡å¼
python concurrent_bigmodel.py \\
    --mode threading \\
    --concurrency 4
```

### Q3: APIé™æµé—®é¢˜ï¼Ÿ

```bash
# å¢åŠ è¯·æ±‚é—´å»¶è¿Ÿ
python concurrent_bigmodel.py \\
    --delay 1.0 \\
    --concurrency 2
```

### Q4: éƒ¨åˆ†ä»»åŠ¡å¤±è´¥ï¼Ÿ

```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
tail -n 50 concurrent_bigmodel.log

# æˆ–æŸ¥çœ‹ç»“æœæ–‡ä»¶ä¸­çš„é”™è¯¯ä¿¡æ¯
python -c "
import json
with open('results.json') as f:
    data = json.load(f)
    for result in data['results']:
        if not result['success']:
            print(f'å¤±è´¥ä»»åŠ¡: {result[\"topic\"]} - {result[\"error_message\"]}')
"
```

## æµ‹è¯•å’ŒéªŒè¯

### 1. è¿è¡Œæµ‹è¯•å¥—ä»¶

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•
python test_concurrent.py

# å•ç‹¬æµ‹è¯•æŸç§æ¨¡å¼  
python -c "
from test_concurrent import test_multiprocessing
test_multiprocessing()
"
```

### 2. æ€§èƒ½åŸºå‡†æµ‹è¯•

```bash
# æ¯”è¾ƒä¸åŒå¹¶å‘æ•°çš„æ€§èƒ½
for i in 1 2 4 8; do
    echo "æµ‹è¯•å¹¶å‘æ•°: $i"
    time python concurrent_bigmodel.py \\
        --concurrency $i \\
        --topics "AI" "åŒºå—é“¾" \\
        --quiet
done
```

### 3. å‹åŠ›æµ‹è¯•

```bash
# å¤§é‡è¯é¢˜å‹åŠ›æµ‹è¯•
python concurrent_bigmodel.py \\
    --topics $(seq 1 50 | sed 's/^/è¯é¢˜_/') \\
    --concurrency 8 \\
    --mode threading \\
    --output stress_test_results.json
```

## ç¤ºä¾‹è„šæœ¬

### 1. æ‰¹é‡åˆ†æè„šæœ¬

```bash
#!/bin/bash
# batch_analysis.sh

TOPICS=(
    "äººå·¥æ™ºèƒ½æœ€æ–°è¿›å±•"
    "æ–°èƒ½æºæ±½è½¦å‘å±•"  
    "åŒ»ç–—ç§‘æŠ€åˆ›æ–°"
    "æ™ºèƒ½åˆ¶é€ è¶‹åŠ¿"
    "é‡‘èç§‘æŠ€å‘å±•"
    "äº‘è®¡ç®—æŠ€æœ¯"
    "åŒºå—é“¾åº”ç”¨"
    "ç‰©è”ç½‘å‘å±•"
    "5GæŠ€æœ¯è¿›å±•"
    "é‡å­è®¡ç®—ç ”ç©¶"
)

python concurrent_bigmodel.py \\
    --topics "${TOPICS[@]}" \\
    --concurrency 6 \\
    --mode multiprocessing \\
    --iterations 2 \\
    --output "batch_analysis_$(date +%Y%m%d_%H%M%S).json"
```

### 2. å®šæ—¶æ‰§è¡Œè„šæœ¬

```bash
#!/bin/bash
# scheduled_analysis.sh

# æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡åˆ†æ
while true; do
    echo "å¼€å§‹å®šæ—¶åˆ†æ: $(date)"
    
    python concurrent_bigmodel.py \\
        --topics "ç§‘æŠ€çƒ­ç‚¹" "å¸‚åœºåŠ¨æ€" "æ”¿ç­–è§£è¯»" \\
        --concurrency 4 \\
        --quiet \\
        --output "hourly_analysis_$(date +%Y%m%d_%H).json"
    
    echo "åˆ†æå®Œæˆï¼Œç­‰å¾…ä¸‹æ¬¡æ‰§è¡Œ..."
    sleep 3600  # ç­‰å¾…1å°æ—¶
done
```

## é›†æˆä½¿ç”¨

### 1. Pythonè„šæœ¬é›†æˆ

```python
from concurrent_bigmodel import ConcurrentBigModelExecutor, ConcurrentConfig

# åˆ›å»ºé…ç½®
config = ConcurrentConfig(
    concurrency=6,
    mode="threading",
    timeout=120
)

# åˆ›å»ºæ‰§è¡Œå™¨
executor = ConcurrentBigModelExecutor(
    config=config,
    api_key="your_api_key"
)

# æ‰§è¡Œåˆ†æ
topics = ["AIæŠ€æœ¯", "æ–°èƒ½æº", "åŒ»ç–—ç§‘æŠ€"]
results = executor.execute_concurrent(topics, iterations=1)

# å¤„ç†ç»“æœ
for result in results:
    if result.success:
        print(f"è¯é¢˜: {result.topic}")
        print(f"åˆ†æ: {result.analysis[:200]}...")
    else:
        print(f"å¤±è´¥: {result.topic} - {result.error_message}")
```

### 2. APIå°è£…ç¤ºä¾‹

```python
from flask import Flask, request, jsonify
from concurrent_bigmodel import ConcurrentBigModelExecutor, ConcurrentConfig

app = Flask(__name__)

@app.route('/analyze', methods=['POST'])
def analyze_topics():
    data = request.json
    topics = data.get('topics', [])
    concurrency = data.get('concurrency', 4)
    
    config = ConcurrentConfig(concurrency=concurrency)
    executor = ConcurrentBigModelExecutor(config, api_key="your_key")
    
    results = executor.execute_concurrent(topics)
    
    return jsonify({
        'results': [asdict(result) for result in results]
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

## æœ€ä½³å®è·µ

1. **åˆç†è®¾ç½®å¹¶å‘æ•°**: æ ¹æ®æœºå™¨æ€§èƒ½å’Œç½‘ç»œæ¡ä»¶è°ƒæ•´
2. **é€‰æ‹©åˆé€‚æ¨¡å¼**: I/Oå¯†é›†ç”¨threading/asyncioï¼ŒCPUå¯†é›†ç”¨multiprocessing
3. **ç›‘æ§èµ„æºä½¿ç”¨**: å…³æ³¨CPUã€å†…å­˜ã€ç½‘ç»œä½¿ç”¨æƒ…å†µ
4. **å¤„ç†å¤±è´¥ä»»åŠ¡**: è®¾ç½®åˆç†çš„è¶…æ—¶å’Œé‡è¯•æœºåˆ¶
5. **ä¿å­˜æ‰§è¡Œç»“æœ**: ä¾¿äºåç»­åˆ†æå’Œå®¡è®¡
6. **ä½¿ç”¨LangSmithè¿½è¸ª**: å¸®åŠ©è°ƒè¯•å’Œæ€§èƒ½ä¼˜åŒ–

## æ”¯æŒå’Œåé¦ˆ

å¦‚æœé‡åˆ°é—®é¢˜æˆ–æœ‰å»ºè®®ï¼Œè¯·ï¼š

1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ `concurrent_bigmodel.log`
2. è¿è¡Œæµ‹è¯•è„šæœ¬ `python test_concurrent.py`
3. æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå¯†é’¥é…ç½®
4. è°ƒæ•´å¹¶å‘å‚æ•°å’Œè¶…æ—¶è®¾ç½®