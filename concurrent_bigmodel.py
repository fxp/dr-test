#!/usr/bin/env python3
"""å¹¶å‘æ‰§è¡ŒBigModelåˆ†æçš„è„šæœ¬

è¿™ä¸ªè„šæœ¬åŸºäºbigmodel_loop.pyï¼Œæ·»åŠ äº†å¹¶å‘æ‰§è¡Œèƒ½åŠ›ï¼š
- æ”¯æŒNä¸ªå¹¶å‘workeråŒæ—¶å¤„ç†ä¸åŒçš„è¯é¢˜
- æä¾›å¤šç§å¹¶å‘æ¨¡å¼ï¼šmultiprocessing, threading, asyncio
- æ”¯æŒæ‰¹é‡å¤„ç†å’Œå®æ—¶å¤„ç†æ¨¡å¼
- å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œè¿›åº¦ç›‘æ§
- å…¼å®¹LangSmithè¿½è¸ª

ä½¿ç”¨ç¤ºä¾‹:
    # ä½¿ç”¨4ä¸ªè¿›ç¨‹å¹¶å‘å¤„ç†
    python concurrent_bigmodel.py --topics "AIæŠ€æœ¯" "æ–°èƒ½æº" "åŒ»ç–—ç§‘æŠ€" "æ™ºèƒ½åˆ¶é€ " --concurrency 4 --mode multiprocess

    # ä½¿ç”¨8ä¸ªçº¿ç¨‹å¹¶å‘å¤„ç†
    python concurrent_bigmodel.py --topics "AIæŠ€æœ¯" "æ–°èƒ½æº" --concurrency 8 --mode threading --iterations 3

    # ä½¿ç”¨å¼‚æ­¥æ¨¡å¼å¤„ç†
    python concurrent_bigmodel.py --topics "AIæŠ€æœ¯" "æ–°èƒ½æº" --concurrency 4 --mode asyncio --batch-size 10
"""

import argparse
import asyncio
import json
import logging
import multiprocessing as mp
import os
import sys
import threading
import time
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional, Union, Iterator
from queue import Queue
import signal

from dotenv import load_dotenv

# å¯¼å…¥åŸå§‹æ¨¡å—çš„å¿…è¦ç»„ä»¶
from bigmodel_loop import (
    BigModelClient, 
    build_analysis_prompt, 
    DEFAULT_CHAT_MODEL, 
    DEFAULT_TOOL_MODEL
)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(processName)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('concurrent_bigmodel.log')
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class TaskResult:
    """å•ä¸ªä»»åŠ¡çš„ç»“æœ"""
    topic: str
    success: bool
    analysis: Optional[str] = None
    search_results_count: int = 0
    error_message: Optional[str] = None
    execution_time: float = 0.0
    worker_id: Optional[str] = None
    timestamp: str = ""


@dataclass 
class ConcurrentConfig:
    """å¹¶å‘æ‰§è¡Œé…ç½®"""
    concurrency: int = 4
    mode: str = "multiprocessing"  # multiprocessing, threading, asyncio
    batch_size: int = 0  # 0è¡¨ç¤ºä¸ä½¿ç”¨æ‰¹å¤„ç†
    timeout: int = 120  # å•ä¸ªä»»åŠ¡è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    max_retries: int = 2  # æœ€å¤§é‡è¯•æ¬¡æ•°
    delay_between_tasks: float = 0.5  # ä»»åŠ¡é—´å»¶è¿Ÿ
    progress_interval: int = 5  # è¿›åº¦æŠ¥å‘Šé—´éš”ï¼ˆç§’ï¼‰


class TaskWorker:
    """ä»»åŠ¡å·¥ä½œå™¨ - å¤„ç†å•ä¸ªåˆ†æä»»åŠ¡"""
    
    def __init__(self, api_key: str, chat_model: str, tool_model: str, worker_id: str):
        self.api_key = api_key
        self.chat_model = chat_model 
        self.tool_model = tool_model
        self.worker_id = worker_id
        self._client = None
    
    @property
    def client(self) -> BigModelClient:
        """å»¶è¿Ÿåˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆæ”¯æŒmultiprocessingï¼‰"""
        if self._client is None:
            self._client = BigModelClient(api_key=self.api_key)
        return self._client
    
    def process_topic(self, topic: str) -> TaskResult:
        """å¤„ç†å•ä¸ªè¯é¢˜åˆ†æ"""
        start_time = time.time()
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        
        try:
            logger.info(f"Worker {self.worker_id} å¼€å§‹å¤„ç†è¯é¢˜: {topic}")
            
            # æœç´¢é˜¶æ®µ
            search_results = self.client.web_search(topic, model=self.tool_model)
            
            # æ‰“å° Worker æœç´¢ç»“æœæ‘˜è¦
            print(f"ğŸ” [{self.worker_id}] æœç´¢å®Œæˆ: '{topic}' -> {len(search_results)} ä¸ªç»“æœ")
            if search_results:
                # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç»“æœçš„æ ‡é¢˜ä½œä¸ºéªŒè¯
                first_result = search_results[0]
                title = first_result.get('title', 'æ— æ ‡é¢˜')[:40]
                print(f"ğŸ“„ [{self.worker_id}] é¦–ä¸ªç»“æœ: {title}...")
            
            # æ„å»ºåˆ†æprompt
            prompt = build_analysis_prompt(topic, search_results)
            messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸“ä¸šçš„ä¸­æ–‡å•†ä¸šåˆ†æé¡¾é—®ï¼Œå›ç­”æ—¶è¯·ä½¿ç”¨ç®€æ´çš„ä¸­æ–‡æ®µè½å¹¶åˆ†ç‚¹åˆ—å‡ºç»“è®ºã€‚",
                },
                {
                    "role": "user", 
                    "content": prompt,
                },
            ]
            
            # åˆ†æé˜¶æ®µ
            analysis = self.client.chat_completion(messages, model=self.chat_model)
            
            execution_time = time.time() - start_time
            
            logger.info(f"Worker {self.worker_id} å®Œæˆè¯é¢˜ '{topic}' (è€—æ—¶: {execution_time:.2f}s)")
            
            return TaskResult(
                topic=topic,
                success=True,
                analysis=analysis,
                search_results_count=len(search_results),
                execution_time=execution_time,
                worker_id=self.worker_id,
                timestamp=timestamp
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = f"å¤„ç†è¯é¢˜ '{topic}' æ—¶å‡ºé”™: {str(e)}"
            logger.error(f"Worker {self.worker_id}: {error_msg}")
            
            return TaskResult(
                topic=topic,
                success=False,
                error_message=error_msg,
                execution_time=execution_time,
                worker_id=self.worker_id,
                timestamp=timestamp
            )


def process_topic_multiprocessing(args_tuple) -> TaskResult:
    """å¤šè¿›ç¨‹å¤„ç†å‡½æ•° - å…¨å±€å‡½æ•°ä»¥æ”¯æŒpickle"""
    api_key, chat_model, tool_model, worker_id, topic = args_tuple
    worker = TaskWorker(api_key, chat_model, tool_model, worker_id)
    return worker.process_topic(topic)


class ConcurrentBigModelExecutor:
    """å¹¶å‘BigModelæ‰§è¡Œå™¨"""
    
    def __init__(self, config: ConcurrentConfig, api_key: str, 
                 chat_model: str = DEFAULT_CHAT_MODEL, 
                 tool_model: str = DEFAULT_TOOL_MODEL):
        self.config = config
        self.api_key = api_key
        self.chat_model = chat_model
        self.tool_model = tool_model
        self.results: List[TaskResult] = []
        self._stop_event = threading.Event()
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨ - ä¼˜é›…åœæ­¢"""
        logger.info(f"æ¥æ”¶åˆ°ä¿¡å· {signum}, æ­£åœ¨ä¼˜é›…åœæ­¢...")
        self._stop_event.set()
    
    def execute_concurrent(self, topics: List[str], iterations: int = 1) -> List[TaskResult]:
        """æ‰§è¡Œå¹¶å‘åˆ†æ"""
        all_results = []
        
        # å¤„ç†iterations=0çš„æƒ…å†µï¼ˆæ— é™æ‰§è¡Œï¼‰
        if iterations == 0:
            logger.info("å¯åŠ¨æ— é™æ‰§è¡Œæ¨¡å¼ (iterations=0)")
            iteration = 1
            while not self._stop_event.is_set():
                logger.info(f"å¼€å§‹ç¬¬ {iteration} è½®å¹¶å‘åˆ†æ (æ— é™æ¨¡å¼)")
                logger.info(f"è¯é¢˜æ•°é‡: {len(topics)}, å¹¶å‘åº¦: {self.config.concurrency}, æ¨¡å¼: {self.config.mode}")
                
                # æ‰§è¡Œæœ¬è½®åˆ†æ
                if self.config.mode == "multiprocessing":
                    results = self._execute_multiprocessing(topics, iteration)
                elif self.config.mode == "threading":
                    results = self._execute_threading(topics, iteration)
                elif self.config.mode == "asyncio":
                    results = self._execute_asyncio(topics, iteration)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„å¹¶å‘æ¨¡å¼: {self.config.mode}")
                
                all_results.extend(results)
                
                # æŠ¥å‘Šæœ¬è½®ç»“æœ
                self._report_iteration_results(results, iteration)
                
                iteration += 1
                
                # è½®æ¬¡é—´å»¶è¿Ÿ
                if not self._stop_event.is_set():
                    logger.info(f"ç­‰å¾… {self.config.delay_between_tasks} ç§’åå¼€å§‹ä¸‹ä¸€è½®...")
                    time.sleep(self.config.delay_between_tasks)
        else:
            # æ­£å¸¸çš„æœ‰é™æ¬¡æ•°æ‰§è¡Œ
            for iteration in range(1, iterations + 1):
                if self._stop_event.is_set():
                    logger.info("æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œç»ˆæ­¢æ‰§è¡Œ")
                    break
                    
                logger.info(f"å¼€å§‹ç¬¬ {iteration}/{iterations} è½®å¹¶å‘åˆ†æ")
                logger.info(f"è¯é¢˜æ•°é‡: {len(topics)}, å¹¶å‘åº¦: {self.config.concurrency}, æ¨¡å¼: {self.config.mode}")
                
                # æ ¹æ®æ¨¡å¼é€‰æ‹©æ‰§è¡Œæ–¹æ³•
                if self.config.mode == "multiprocessing":
                    results = self._execute_multiprocessing(topics, iteration)
                elif self.config.mode == "threading":
                    results = self._execute_threading(topics, iteration)
                elif self.config.mode == "asyncio":
                    results = self._execute_asyncio(topics, iteration)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„å¹¶å‘æ¨¡å¼: {self.config.mode}")
                
                all_results.extend(results)
                
                # æŠ¥å‘Šæœ¬è½®ç»“æœ
                self._report_iteration_results(results, iteration)
                
                # è½®æ¬¡é—´å»¶è¿Ÿ
                if iteration < iterations and not self._stop_event.is_set():
                    logger.info(f"ç­‰å¾… {self.config.delay_between_tasks} ç§’åå¼€å§‹ä¸‹ä¸€è½®...")
                    time.sleep(self.config.delay_between_tasks)
        
        return all_results
    
    def _execute_multiprocessing(self, topics: List[str], iteration: int) -> List[TaskResult]:
        """å¤šè¿›ç¨‹æ‰§è¡Œ"""
        logger.info(f"ä½¿ç”¨å¤šè¿›ç¨‹æ¨¡å¼ï¼Œè¿›ç¨‹æ•°: {self.config.concurrency}")
        
        # å‡†å¤‡ä»»åŠ¡å‚æ•°
        task_args = [
            (self.api_key, self.chat_model, self.tool_model, f"P{i%self.config.concurrency}-{iteration}", topic)
            for i, topic in enumerate(topics)
        ]
        
        results = []
        
        with ProcessPoolExecutor(max_workers=self.config.concurrency) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_topic = {
                executor.submit(process_topic_multiprocessing, args): args[4] 
                for args in task_args
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_topic, timeout=self.config.timeout * len(topics)):
                try:
                    result = future.result(timeout=self.config.timeout)
                    results.append(result)
                except Exception as e:
                    topic = future_to_topic[future]
                    logger.error(f"å¤„ç†è¯é¢˜ '{topic}' æ—¶å‡ºé”™: {e}")
                    results.append(TaskResult(
                        topic=topic,
                        success=False,
                        error_message=str(e),
                        timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
                    ))
                
                # åœ¨æ”¶é›†ç»“æœåæ£€æŸ¥åœæ­¢ä¿¡å·
                if self._stop_event.is_set():
                    logger.info("æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œç»ˆæ­¢åç»­ä»»åŠ¡æ”¶é›†")
                    break
        
        return results
    
    def _execute_threading(self, topics: List[str], iteration: int) -> List[TaskResult]:
        """å¤šçº¿ç¨‹æ‰§è¡Œ"""
        logger.info(f"ä½¿ç”¨å¤šçº¿ç¨‹æ¨¡å¼ï¼Œçº¿ç¨‹æ•°: {self.config.concurrency}")
        
        results = []
        
        with ThreadPoolExecutor(max_workers=self.config.concurrency) as executor:
            # åˆ›å»ºworkerså¹¶æäº¤ä»»åŠ¡
            future_to_topic = {}
            
            for i, topic in enumerate(topics):
                if self._stop_event.is_set():
                    break
                    
                worker_id = f"T{i%self.config.concurrency}-{iteration}"
                worker = TaskWorker(self.api_key, self.chat_model, self.tool_model, worker_id)
                future = executor.submit(worker.process_topic, topic)
                future_to_topic[future] = topic
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_topic, timeout=self.config.timeout * len(topics)):
                try:
                    result = future.result(timeout=self.config.timeout)
                    results.append(result)
                except Exception as e:
                    topic = future_to_topic[future]
                    logger.error(f"å¤„ç†è¯é¢˜ '{topic}' æ—¶å‡ºé”™: {e}")
                    results.append(TaskResult(
                        topic=topic,
                        success=False,
                        error_message=str(e),
                        timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
                    ))
                
                # åœ¨æ”¶é›†ç»“æœåæ£€æŸ¥åœæ­¢ä¿¡å·
                if self._stop_event.is_set():
                    logger.info("æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œç»ˆæ­¢åç»­ä»»åŠ¡æ”¶é›†")
                    break
        
        return results
    
    def _execute_asyncio(self, topics: List[str], iteration: int) -> List[TaskResult]:
        """å¼‚æ­¥æ‰§è¡Œ"""
        logger.info(f"ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œå¹¶å‘åº¦: {self.config.concurrency}")
        
        # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥ä»»åŠ¡
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(self._async_execute_topics(topics, iteration))
    
    async def _async_execute_topics(self, topics: List[str], iteration: int) -> List[TaskResult]:
        """å¼‚æ­¥æ‰§è¡Œè¯é¢˜åˆ†æ"""
        semaphore = asyncio.Semaphore(self.config.concurrency)
        
        async def process_topic_async(topic: str, worker_id: str) -> TaskResult:
            async with semaphore:
                # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥çš„APIè°ƒç”¨
                loop = asyncio.get_event_loop()
                worker = TaskWorker(self.api_key, self.chat_model, self.tool_model, worker_id)
                result = await loop.run_in_executor(None, worker.process_topic, topic)
                return result
        
        # åˆ›å»ºæ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
        tasks = [
            process_topic_async(topic, f"A{i%self.config.concurrency}-{iteration}")
            for i, topic in enumerate(topics)
        ]
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                topic = topics[i]
                logger.error(f"å¼‚æ­¥å¤„ç†è¯é¢˜ '{topic}' æ—¶å‡ºé”™: {result}")
                processed_results.append(TaskResult(
                    topic=topic,
                    success=False,
                    error_message=str(result),
                    timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
                ))
            else:
                processed_results.append(result)
        
        return processed_results
    
    def _report_iteration_results(self, results: List[TaskResult], iteration: int):
        """æŠ¥å‘Šå•è½®ç»“æœ"""
        successful = [r for r in results if r.success]
        failed = [r for r in results if not r.success]
        
        total_time = sum(r.execution_time for r in results)
        avg_time = total_time / len(results) if results else 0
        
        logger.info(f"ç¬¬ {iteration} è½®å®Œæˆ:")
        logger.info(f"  æ€»ä»»åŠ¡æ•°: {len(results)}")
        logger.info(f"  æˆåŠŸ: {len(successful)}")
        logger.info(f"  å¤±è´¥: {len(failed)}")
        logger.info(f"  æ€»è€—æ—¶: {total_time:.2f}s")
        logger.info(f"  å¹³å‡è€—æ—¶: {avg_time:.2f}s")
        
        if failed:
            logger.warning("å¤±è´¥çš„è¯é¢˜:")
            for result in failed:
                logger.warning(f"  - {result.topic}: {result.error_message}")
    
    def save_results(self, results: List[TaskResult], output_file: str = None):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        if not output_file:
            output_file = f"concurrent_results_{int(time.time())}.json"
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        serializable_results = [asdict(result) for result in results]
        
        # æ·»åŠ æ±‡æ€»ä¿¡æ¯
        summary = {
            "total_tasks": len(results),
            "successful_tasks": len([r for r in results if r.success]),
            "failed_tasks": len([r for r in results if not r.success]),
            "total_execution_time": sum(r.execution_time for r in results),
            "average_execution_time": sum(r.execution_time for r in results) / len(results) if results else 0,
            "config": asdict(self.config),
            "models": {
                "chat_model": self.chat_model,
                "tool_model": self.tool_model
            }
        }
        
        output_data = {
            "summary": summary,
            "results": serializable_results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    def print_results_summary(self, results: List[TaskResult]):
        """æ‰“å°ç»“æœæ‘˜è¦"""
        successful = [r for r in results if r.success]
        failed = [r for r in results if not r.success]
        
        print("\n" + "="*60)
        print("å¹¶å‘æ‰§è¡Œç»“æœæ‘˜è¦")
        print("="*60)
        print(f"æ€»ä»»åŠ¡æ•°: {len(results)}")
        
        if len(results) > 0:
            print(f"æˆåŠŸ: {len(successful)} ({len(successful)/len(results)*100:.1f}%)")
            print(f"å¤±è´¥: {len(failed)} ({len(failed)/len(results)*100:.1f}%)")
        else:
            print("æˆåŠŸ: 0 (0.0%)")
            print("å¤±è´¥: 0 (0.0%)")
        
        if results:
            total_time = sum(r.execution_time for r in results)
            print(f"æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f}s")
            print(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {total_time/len(results):.2f}s")
        
        # æŒ‰workerç»Ÿè®¡
        worker_stats = {}
        for result in results:
            if result.worker_id:
                if result.worker_id not in worker_stats:
                    worker_stats[result.worker_id] = {"success": 0, "failed": 0, "time": 0}
                
                if result.success:
                    worker_stats[result.worker_id]["success"] += 1
                else:
                    worker_stats[result.worker_id]["failed"] += 1
                worker_stats[result.worker_id]["time"] += result.execution_time
        
        if worker_stats:
            print(f"\nWorker ç»Ÿè®¡:")
            for worker_id, stats in sorted(worker_stats.items()):
                print(f"  {worker_id}: {stats['success']}æˆåŠŸ/{stats['failed']}å¤±è´¥, è€—æ—¶:{stats['time']:.1f}s")
        
        # æ˜¾ç¤ºå¤±è´¥çš„ä»»åŠ¡
        if failed:
            print(f"\nå¤±è´¥çš„ä»»åŠ¡ ({len(failed)}):")
            for result in failed:
                print(f"  - {result.topic}: {result.error_message}")
        
        # æ˜¾ç¤ºæˆåŠŸä»»åŠ¡çš„æ ·ä¾‹
        if successful:
            print(f"\næˆåŠŸä»»åŠ¡æ ·ä¾‹:")
            sample = successful[0]
            print(f"  è¯é¢˜: {sample.topic}")
            print(f"  æœç´¢ç»“æœæ•°: {sample.search_results_count}")
            print(f"  åˆ†æé•¿åº¦: {len(sample.analysis or '') if sample.analysis else 0} å­—ç¬¦")
            print(f"  æ‰§è¡Œæ—¶é—´: {sample.execution_time:.2f}s")
            if sample.analysis:
                preview = sample.analysis[:200] + "..." if len(sample.analysis) > 200 else sample.analysis
                print(f"  åˆ†æé¢„è§ˆ: {preview}")


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="å¹¶å‘æ‰§è¡ŒBigModelåˆ†æ")
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument(
        "--api-key",
        default=os.getenv("BIGMODEL_API_KEY"),
        help="BigModel API key"
    )
    parser.add_argument(
        "--topics", 
        nargs="*",
        default=["äººå·¥æ™ºèƒ½çƒ­ç‚¹", "æ–°èƒ½æºäº§ä¸š", "åŒ»ç–—ç§‘æŠ€åˆ›æ–°", "æ™ºèƒ½åˆ¶é€ ", "é‡‘èç§‘æŠ€"],
        help="è¦åˆ†æçš„è¯é¢˜åˆ—è¡¨"
    )
    parser.add_argument(
        "--iterations",
        type=int, 
        default=1,
        help="æ‰§è¡Œè½®æ•° (0=æ— é™æ‰§è¡Œï¼Œç›´åˆ°æ‰‹åŠ¨åœæ­¢)"
    )
    
    # å¹¶å‘å‚æ•°
    parser.add_argument(
        "--concurrency", "-c",
        type=int,
        default=4, 
        help="å¹¶å‘æ•°é‡ (è¿›ç¨‹/çº¿ç¨‹æ•°)"
    )
    parser.add_argument(
        "--mode", "-m",
        choices=["multiprocessing", "threading", "asyncio"],
        default="multiprocessing",
        help="å¹¶å‘æ¨¡å¼"
    )
    parser.add_argument(
        "--batch-size", "-b",
        type=int,
        default=0,
        help="æ‰¹å¤„ç†å¤§å° (0=ä¸ä½¿ç”¨æ‰¹å¤„ç†)"
    )
    parser.add_argument(
        "--timeout", "-t",
        type=int,
        default=120,
        help="å•ä»»åŠ¡è¶…æ—¶æ—¶é—´(ç§’)"
    )
    parser.add_argument(
        "--max-retries",
        type=int,
        default=2,
        help="æœ€å¤§é‡è¯•æ¬¡æ•°"
    )
    parser.add_argument(
        "--delay",
        type=float,
        default=0.5,
        help="ä»»åŠ¡é—´å»¶è¿Ÿ(ç§’)"
    )
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument(
        "--chat-model",
        default=DEFAULT_CHAT_MODEL,
        help="èŠå¤©æ¨¡å‹åç§°"
    )
    parser.add_argument(
        "--tool-model", 
        default=DEFAULT_TOOL_MODEL,
        help="å·¥å…·æ¨¡å‹åç§°"
    )
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument(
        "--output", "-o",
        help="ç»“æœè¾“å‡ºæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="é™é»˜æ¨¡å¼ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º"
    )
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # é…ç½®æ—¥å¿—çº§åˆ«
    if args.quiet:
        logging.getLogger().setLevel(logging.WARNING)
    
    # éªŒè¯API key
    if not args.api_key:
        logger.error("ç¼ºå°‘ BIGMODEL_API_KEYï¼Œè¯·é€šè¿‡ --api-key å‚æ•°æˆ–ç¯å¢ƒå˜é‡æä¾›")
        return 1
    
    # åˆ›å»ºå¹¶å‘é…ç½®
    config = ConcurrentConfig(
        concurrency=args.concurrency,
        mode=args.mode,
        batch_size=args.batch_size,
        timeout=args.timeout,
        max_retries=args.max_retries,
        delay_between_tasks=args.delay
    )
    
    # åˆ›å»ºæ‰§è¡Œå™¨
    executor = ConcurrentBigModelExecutor(
        config=config,
        api_key=args.api_key,
        chat_model=args.chat_model,
        tool_model=args.tool_model
    )
    
    try:
        logger.info("å¼€å§‹å¹¶å‘æ‰§è¡ŒBigModelåˆ†æ")
        logger.info(f"é…ç½®: {asdict(config)}")
        
        # æ‰§è¡Œåˆ†æ
        start_time = time.time()
        results = executor.execute_concurrent(args.topics, args.iterations)
        total_time = time.time() - start_time
        
        logger.info(f"æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}s")
        
        # ä¿å­˜ç»“æœ
        if args.output:
            executor.save_results(results, args.output)
        else:
            executor.save_results(results)
        
        # æ‰“å°æ‘˜è¦
        if not args.quiet:
            executor.print_results_summary(results)
        
        return 0
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        return 1
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    # æ”¯æŒå¤šè¿›ç¨‹
    mp.freeze_support()
    sys.exit(main())